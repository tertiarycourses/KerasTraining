{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learner/Facilitator Guide for Deep Learning with Keras - 30 Jul 2021",
      "provenance": [],
      "collapsed_sections": [
        "uePIrjqGAJDw",
        "gU306MXBcZQU",
        "jOSyztU1ccDh",
        "Ta0n4LpecmZb",
        "WKgjQ1Cp3ck2",
        "dYHoIlOnTOIx",
        "X0t-WVkCUb6S",
        "9hi9pgiAb_Wc",
        "bj0_-g09jL-S",
        "mbl5w8vDjTwU",
        "gfhIrE2fDRDv",
        "6VgV9NCaZxUb",
        "4kFBAGkA97hH",
        "SuR1qtSVAu1a",
        "WGzjGBNsD2Zn",
        "OZOBUJ02-rA9",
        "xr7i2L08IIp5",
        "uvht4o67PiUU",
        "9wEuxiX_j56O",
        "cN_Ku2X91WlQ",
        "jPXFAwUl1b5V",
        "WgQGI9_41fSJ",
        "uY6tbfDe1j3k",
        "BgViJ2IO1ndb",
        "oD3qK9B4liVT",
        "TO3WCmo2nB-Q",
        "mQjlvPJKbuz1",
        "TsnfnOpnb5WG",
        "82INGsfHb_40",
        "KvXRTJg9cGVC",
        "xdCaSULmc786",
        "4Ta9YWWZdbiF",
        "D6mpaNGixeDu",
        "YRck3uIwyeLo",
        "6naCWJHxygNk",
        "u4eKE0nEyxfk",
        "kMaVg1zTKCIG",
        "1HeWq_7zY6oh",
        "G_aEYm4PVptX",
        "p_rU994OlLbm",
        "4VI_2v-MlQT5",
        "AliO7-3ZVY0R",
        "TRJT2KYRVlyB",
        "WExIKZPn3qX-",
        "Ij_t2sHPkNoF",
        "USwnLWZgajKz",
        "D4jRBKpSB-Ss",
        "loQBoU1AFk66",
        "jE7Rj815AXks",
        "8IWFB2XTDGQs",
        "3eFpPIeZAabY",
        "N49NrPlcAddg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uePIrjqGAJDw"
      },
      "source": [
        "# Topic 1 Introduction to Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tKfHLCoEWhs"
      },
      "source": [
        "## Setup Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeTTuPEjwGcd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"Version: \", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GISVAwjU9PU-"
      },
      "source": [
        "## Basic Tensorflow Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS9iF4AwcWKt"
      },
      "source": [
        "### Tensor and Constant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLBI18if63u9"
      },
      "source": [
        "a = tf.constant(4,dtype=tf.float32)\n",
        "b = tf.constant(5.6,dtype=tf.float32)\n",
        "c = a*b\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLEytH1am9ZY"
      },
      "source": [
        "c.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Do6TJkdxNPp"
      },
      "source": [
        "a = tf.constant(4)\n",
        "b = tf.constant(5.6)\n",
        "print(a*b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7BmWKDNTudj"
      },
      "source": [
        "a = tf.constant([1,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ntk8k09ceLy"
      },
      "source": [
        "### Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIag4x_q7vtK"
      },
      "source": [
        "a = tf.constant([[1,2],[3,4]])\n",
        "b = tf.constant([[5,6],[7,8]])\n",
        "c = tf.matmul(a,b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y62th6uynGE-"
      },
      "source": [
        "c.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLYPxjCcP2P"
      },
      "source": [
        "### Activity: Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pem37r1W8rqj"
      },
      "source": [
        "x = tf.constant([[1.1,1.2]],dtype=tf.float32)\n",
        "w = tf.constant([[1,2],[3,4]],dtype=tf.float32)\n",
        "b = tf.constant([[2.3,2.5]],dtype=tf.float32)\n",
        "y = tf.matmul(x,w)+b\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKgjQ1Cp3ck2"
      },
      "source": [
        "# Topic 2 Neural Networks for Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1WP-Y6cTHOJ"
      },
      "source": [
        "### Step 1: Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NklScv9T4Qin"
      },
      "source": [
        "import pandas as pd\n",
        "dataset_path = \"https://raw.githubusercontent.com/tertiarycourses/datasets/master/boston.csv\"                     \n",
        "dataset = pd.read_csv(dataset_path)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEnw4DOK4paU"
      },
      "source": [
        "x_train = dataset.sample(frac=0.7,random_state=0)\n",
        "x_test = dataset.drop(x_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyf4b2peeaIx"
      },
      "source": [
        "y_train = x_train.pop('medv')\n",
        "y_test = x_test.pop('medv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9p5Xxxr7OUK"
      },
      "source": [
        "x_train = (x_train - x_train.mean())/(x_train.max()-x_train.min())\n",
        "x_test = (x_test - x_test.mean())/(x_test.max()-x_test.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYHoIlOnTOIx"
      },
      "source": [
        "### Step 2: Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0icWR2jozrFQ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu',input_dim=13))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVzmAP0T5c1t"
      },
      "source": [
        "### Step 3: Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nT2BAqZ1bgn"
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui4mp-xbQnch"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sQQ0-OwJGV5"
      },
      "source": [
        "### Visualize the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfWmmre_Gxvn"
      },
      "source": [
        "tf.keras.utils.plot_model(model, 'my_first_model.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_JTBz0UG7Uk"
      },
      "source": [
        "tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Q-M1B6TUoS"
      },
      "source": [
        "### Step 4: Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaEA22PM7u-c"
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(x_train, y_train,epochs=EPOCHS,shuffle=True,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNHRRuO5Taiu"
      },
      "source": [
        "### Step 5: Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHuFHb-u1u1I"
      },
      "source": [
        "mse = history.history['mse']\n",
        "epoch = range(len(mse))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epoch,mse,label='mse')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Square Error [MSE]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXq0uWC6jex"
      },
      "source": [
        "y_hat = model.predict(x_test)\n",
        "\n",
        "plt.scatter(y_test, y_hat)\n",
        "plt.xlabel('True Values [Housing Price]')\n",
        "plt.ylabel('Predictions [Housing Price]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 100], [0, 100],'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hi9pgiAb_Wc"
      },
      "source": [
        "### Step 6: Save the Model in HDF5 Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIn_PdWVYWUy"
      },
      "source": [
        "model.save(\"regression.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0_-g09jL-S"
      },
      "source": [
        "#### Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqTRRcZPv8WF"
      },
      "source": [
        "new_model = keras.models.load_model('regression.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbl5w8vDjTwU"
      },
      "source": [
        "#### Save the Model in SavedModel Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8THLTbmwGa4"
      },
      "source": [
        "model.save(\"regression/1/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRIuYbSdwoUr"
      },
      "source": [
        "new_model = keras.models.load_model('regression/1/')\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfhIrE2fDRDv"
      },
      "source": [
        "#### Save and Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhivcJ8DDXZ"
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./regression/1/w')\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('./regression/1/w)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VgV9NCaZxUb"
      },
      "source": [
        "### Exercise: Predictive Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht0cRSNb9seb"
      },
      "source": [
        "#### Step `: Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i576kB-VZwft"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j5Bikh8aUVr"
      },
      "source": [
        "# Load the data\n",
        "X_train = pd.read_csv('book_sales_training.csv')\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxJQ5K88agh9"
      },
      "source": [
        "y = X_train.pop('total_earnings')\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_IJ8nckaiFJ"
      },
      "source": [
        "# Scale the data\n",
        "sc = MinMaxScaler((0,1))\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3a20Cu49wb_"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaT3T4R5a79X"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128,input_dim=9,activation='relu'))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swRl8NFc90XH"
      },
      "source": [
        "#### Step 3: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPA3Q8n7ym7K"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ADAM = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mse', optimizer=ADAM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_67FtRI93tE"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSDblFbWa_rX"
      },
      "source": [
        "history = model.fit(X_train,y,epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICleV9N096NV"
      },
      "source": [
        "#### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFFp6-9EbMj4"
      },
      "source": [
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JATAjHErbRNw"
      },
      "source": [
        "# Load the data\n",
        "X_test = pd.read_csv('https://raw.githubusercontent.com/tertiarycourses/datasets/master/book_sales_testing.csv')\n",
        "\n",
        "y = X_test.pop('total_earnings')\n",
        "\n",
        "# Scale the data\n",
        "sc = MinMaxScaler((0,1))\n",
        "X_test= sc.fit_transform(X_test)\n",
        "\n",
        "yhat = model(X_test)\n",
        "\n",
        "plt.scatter(y,yhat)\n",
        "plt.xlabel('Actual sales')\n",
        "plt.ylabel('Predicted sales')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "plt.plot([0, 300000], [0, 300000],'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kFBAGkA97hH"
      },
      "source": [
        "# Topic 3 Neural Network for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuR1qtSVAu1a"
      },
      "source": [
        "## NN Demo on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtyZurvwcbF"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V0RpO3tw000"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D41u9e5ZykId"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFfmbYnE7gpX"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Fe_T99zIWG"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQI2tECjzkvp"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWe-1joB0A-S"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKFgWbY_7Px0"
      },
      "source": [
        "loss,acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"Accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uVDPhv-7op-"
      },
      "source": [
        "model.save(\"mnist.h5\")\n",
        "\n",
        "# tf.saved_model.save(model, \"/model_mnist/1/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RcuaHhkt7c6"
      },
      "source": [
        "new_model =keras.models.load_model('mnist.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mud-twRruHwK"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGzjGBNsD2Zn"
      },
      "source": [
        "#### Sparse Cross Entropy vs Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXVRqVznDxZ7"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzeVX4k9D9gq"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train,y_test = to_categorical(y_train), to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPm1x4pvEIXP"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB0iNKOjELa2"
      },
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(64,activation='relu'),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dense(10,activation='softmax')\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8r5X3EuBU"
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZVctmXmEz_6"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZOBUJ02-rA9"
      },
      "source": [
        "## Ex: Classification for Fashsion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwcNE9URCjSD"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgrzqfvCrFW"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVFlrswCvds"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epAIFevbCzCc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inRenTUC2Ug"
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L_8D8ooDYeg"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tEK_zvGDb9k"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlwee1LY0CA"
      },
      "source": [
        "# Topic 4 Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WExIKZPn3qX-"
      },
      "source": [
        "## RNN/LSTM/GRU and Input Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eil0Qz01wQDy"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "batch = 5 \n",
        "feature = 10 # could be the embedding size\n",
        "hidden_size = 20 \n",
        "timesteps = 3 # sequence length \n",
        "\n",
        "inputs = np.random.randn(batch, timesteps, feature)\n",
        "rnn = tf.keras.layers.SimpleRNN(hidden_size)\n",
        "\n",
        "h_out = rnn(inputs)\n",
        "print('Output size (batch, hidden_size) = ', h_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lVnB6w-3kw5"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "batch = 5 \n",
        "feature = 10 # could be the embedding size\n",
        "hidden_size = 20 \n",
        "timesteps = 3 # sequence length \n",
        "\n",
        "inputs = np.random.randn(batch, timesteps, feature)\n",
        "lstm = tf.keras.layers.LSTM(hidden_size)\n",
        "\n",
        "h_out = lstm(inputs)\n",
        "print('Output size (batch, hidden_size) = ', h_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOHSlI_Y4iYe"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "batch = 5 \n",
        "feature = 10 # could be the embedding size\n",
        "hidden_size = 20 \n",
        "timesteps = 3 # sequence length \n",
        "\n",
        "inputs = np.random.randn(batch, timesteps, feature)\n",
        "gru = tf.keras.layers.GRU(hidden_size)\n",
        "\n",
        "h_out = gru(inputs)\n",
        "print('Output size (batch, hidden_size) = ', h_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij_t2sHPkNoF"
      },
      "source": [
        "## Time Series Forcasting with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USwnLWZgajKz"
      },
      "source": [
        "### Time Series Forecasting (Airplane Passengers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBGGfiheeuYl"
      },
      "source": [
        "#### Step 1: Preprocess Data (Air Passengers Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv4L0MREJmVW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo49kmPSJw4u"
      },
      "source": [
        "dataset = pd.read_csv('airline-passengers.csv')\n",
        "#dataset = pd.read_csv('DBS.csv',usecols=['Date','Close'])\n",
        "\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiYC3ZimJ63N"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYpeZrh1J_m8"
      },
      "source": [
        "dataset = dataset.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Passengers')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdKEj6D2KFoY"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXbfkvBQKOim"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBJXkUquLjWB"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BJxj21BKtry"
      },
      "source": [
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(X)]\n",
        "y_test = y[train_size:len(y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j14osZEkMjBa"
      },
      "source": [
        "feature = 1\n",
        "hidden_size = 5\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1JDJ9UnNcx-"
      },
      "source": [
        "X_train.shape,X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HCsuSGvO8gF"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrG9wE0Be6Nq"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_UZhe5rMnc4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlC3SUxPj9fC"
      },
      "source": [
        "#### Step 3: Define Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkyJCVlukElc"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H29UjhMkGl4"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwFP9MgoUob3"
      },
      "source": [
        "history = model.fit(trainX, trainY, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAHJy6UYj2EI"
      },
      "source": [
        "#### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HqJV9bW-hDp"
      },
      "source": [
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UME-OkrmVYJF"
      },
      "source": [
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Airline Passengers')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4jRBKpSB-Ss"
      },
      "source": [
        "### Activity: Time Series Forecasting (Shampoo Sales)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfPwtFzMMsum"
      },
      "source": [
        "#### Step 1: Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVyERS5TCMcH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu6leedvCO3y"
      },
      "source": [
        "dataset = pd.read_csv('shampoo.csv')\n",
        "#dataset = pd.read_csv('DBS.csv',usecols=['Date','Close'])\n",
        "\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpGjQIncCiaL"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3bwMFoZCoTN"
      },
      "source": [
        "dataset = dataset.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_6R1Pd-C6G-"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_J6HQ0QDBPO"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3XcFyTcDGgk"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5KtVUVjDXdd"
      },
      "source": [
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(x)]\n",
        "y_test = y[train_size:len(y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7sSZGedD_KK"
      },
      "source": [
        "feature = 1\n",
        "hidden_size = 5\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8IZBFOrMzoD"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYFP5YF2EOAy"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYOqOq16M2nX"
      },
      "source": [
        "#### Step 3: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHTr1pINEVnB"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VT7KZIQM5tG"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMJMbUytEhsH"
      },
      "source": [
        "history = model.fit(trainX, trainY, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-NE3ONSNAgO"
      },
      "source": [
        "#### Step 5: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juHt9hOMEsXK"
      },
      "source": [
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzK2pWW5Ey04"
      },
      "source": [
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Shampoo Sales')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loQBoU1AFk66"
      },
      "source": [
        "### Activity: Stock Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIbyHlONNEch"
      },
      "source": [
        "#### Step 1: Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRdmC-YFmOj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b33ybIGF0Y7"
      },
      "source": [
        "dataset = pd.read_csv('DBS.csv',usecols=['Date','Close'])\n",
        "\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkNmA9zLGG05"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVaku_kZGL8s"
      },
      "source": [
        "dataset = dataset.iloc[:,1:2].values\n",
        "\n",
        "plt.plot(dataset)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2nZgeMZGRFU"
      },
      "source": [
        "def sliding_window(data, seq_length):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(data)-seq_length-1):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        _y = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return np.array(x),np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8DAyY2cGWQk"
      },
      "source": [
        "sc = MinMaxScaler()\n",
        "dataset = sc.fit_transform(dataset)\n",
        "\n",
        "timesteps = 4\n",
        "X,y = sliding_window(dataset, timesteps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqRm6PKHGayh"
      },
      "source": [
        "train_size = int(len(y) * 0.67)\n",
        "test_size = int(len(y)) - train_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRIu1hXjGkle"
      },
      "source": [
        "X_train = X[0:train_size]\n",
        "y_train = y[0:train_size]\n",
        "\n",
        "X_test = X[train_size:len(x)]\n",
        "y_test = y[train_size:len(y)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWYACpXrGo7m"
      },
      "source": [
        "feature = 1\n",
        "hidden_size = 5\n",
        "\n",
        "# inputs: A 3D tensor with shape [batch, timesteps, feature].\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], timesteps, input_size))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], timesteps, 1, input_size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B2sRx7NMFp"
      },
      "source": [
        "#### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt94ktzyGv3m"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(hidden_size, activation='tanh',input_shape=(timesteps,feature)))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sggVP6RNOp5"
      },
      "source": [
        "#### Step 3: Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBL1xEEG1xc"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbQB9oJINShL"
      },
      "source": [
        "#### Step 4: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFjNAbZdG6w6"
      },
      "source": [
        "history = model.fit(trainX, trainY, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hZd313DNVYI"
      },
      "source": [
        "#### Step 5: Evaluate teh Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH6ALXk3HFy8"
      },
      "source": [
        "loss = history.history['loss']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epoch,loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yhd4as3HKnf"
      },
      "source": [
        "yhat = model(X)\n",
        "\n",
        "yhat = sc.inverse_transform(yhat)\n",
        "y_ = sc.inverse_transform(y)\n",
        "\n",
        "plt.axvline(x=train_size, c='g', linestyle='--')\n",
        "\n",
        "plt.plot(y_,'b',label='actual')\n",
        "plt.plot(yhat,'r',label='prediction')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftG5ka_YMyS"
      },
      "source": [
        "## Sentiment Analysis With RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmqPrAWa75W"
      },
      "source": [
        "### Step 1: Load the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6eJ1XvJYREL"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_words = 10000  \n",
        "seq_length = 80  \n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_words)\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=seq_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=seq_length)\n",
        "print('input_train shape:', x_train.shape)\n",
        "print('input_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZ-97-pcFIW"
      },
      "source": [
        "### Step 2: Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s62nbYQoY5Bz"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow. keras.layers import LSTM\n",
        "\n",
        "hidden_size = 32\n",
        "embedding_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_size))\n",
        "model.add(LSTM(hidden_size,activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm-q7PEUcqbM"
      },
      "source": [
        "### Step 3: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI_4DFsVWHjN"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8MPZorXZFhp"
      },
      "source": [
        "batch = 250\n",
        "num_epoch = 10 \n",
        "history = model.fit(x_train, y_train, epochs=num_epoch, batch_size=batch,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTcnxwuMdWST"
      },
      "source": [
        "### Step 4: Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwp6F2TQZNN7"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho31d9npXdJU"
      },
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "#text = \"This movie is lousy and horrible I feel very sad\"\n",
        "#text =\" This movie is very good and nice I feel very happy\"\n",
        "# text = \"This movie is lousy and horrible It is wasting my money\"\n",
        "text =\"This movie is good worth the money I love it\"\n",
        "tokens = text.lower().split()\n",
        "token_index = [word_index[word] for word in tokens]\n",
        "token_index = np.array(token_index)\n",
        "token_index = token_index[np.newaxis,:]\n",
        "\n",
        "pred = model(token_index)\n",
        "print(f'The sentiment score is {pred} - 0 is negative and 1 is positive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCy5Le2o8pSO"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}